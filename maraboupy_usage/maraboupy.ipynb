{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = 'EleutherAI/pythia-160m'\n",
    "model_name = 'EleutherAI/pythia-70m'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model_og = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[25521,  1533]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_input_after_tokenizer(inp: str):\n",
    "\t\ttokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\t\tinp_out = tokenizer(inp, return_tensors=\"pt\")\n",
    "\t\tprint(inp_out)\n",
    "\t\tinputs = inp_out['input_ids'].squeeze(0)\n",
    "\t\t# print(inputs, inputs.shape)\n",
    "\t\t# TODO: IDK ABOUT WHATS GOING ON W/ TOKEN SIZE VS Vocab Size\n",
    "\t\t# Vocab size is 50204 and inp size is 50304\n",
    "\t\tone_hot = torch.zeros((inputs.shape[0], 50304), dtype=torch.int)\n",
    "\t\tfor i in range(inputs.shape[0]):\n",
    "\t\t\tone_hot[i, inputs[i]] = 1\n",
    "\t\t# one_hot[inputs['input_ids'][0, 0]] = 1\n",
    "\t\treturn one_hot#, inp_out['attention_mask']\n",
    "get_input_after_tokenizer('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[25521,  1533]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "inps_one_hot = get_input_after_tokenizer(\"hello world\")\n",
    "seq_len = inps_one_hot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXLayer(\n",
       "  (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (attention): GPTNeoXAttention(\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "    (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (mlp): GPTNeoXMLP(\n",
       "    (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (act): GELUActivation()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_og.gpt_neox.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelSel(\n",
       "  (embed_linear): Linear(in_features=50304, out_features=512, bias=False)\n",
       "  (layer_norm): SimplfiedLayerNorm(\n",
       "    (eps): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (ones_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (ones_linear_neg): Linear(in_features=512, out_features=512, bias=False)\n",
       "  )\n",
       "  (attn): FixedAttentionMask(\n",
       "    (attn): GPTNeoXAttention(\n",
       "      (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "      (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (slice_query): Slicer(\n",
       "      (slicer): Linear(in_features=192, out_features=64, bias=True)\n",
       "    )\n",
       "    (slice_value): Slicer(\n",
       "      (slicer): Linear(in_features=192, out_features=64, bias=True)\n",
       "    )\n",
       "    (slice_key): Slicer(\n",
       "      (slicer): Linear(in_features=192, out_features=64, bias=True)\n",
       "    )\n",
       "    (slice_rotary): Slicer(\n",
       "      (slicer): Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (slice_non_rotary): Slicer(\n",
       "      (slicer): Linear(in_features=64, out_features=48, bias=True)\n",
       "    )\n",
       "    (slice_rorate_half_1): Slicer(\n",
       "      (slicer): Linear(in_features=16, out_features=8, bias=True)\n",
       "    )\n",
       "    (slice_rorate_half_2): Slicer(\n",
       "      (slicer): Linear(in_features=16, out_features=8, bias=True)\n",
       "    )\n",
       "    (QKV_copier): QKVCopier(\n",
       "      (slicer_0): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_1): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_2): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_3): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_4): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_5): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_6): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_7): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simplified import ModelSel\n",
    "\n",
    "model_sel = ModelSel(model_og)\n",
    "model_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1536])\n",
      "QKV SIZE torch.Size([2, 1536]) torch.Size([2])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps_one_hot_formatted = inps_one_hot.float()\n",
    "# embed_linear.forward(inps_one_hot).shape\n",
    "model_sel(inps_one_hot_formatted).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inps_one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14669/3575411511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minps_one_hot_formatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minps_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m torch.onnx.export(model_sel, inps_one_hot_formatted,\n\u001b[1;32m      3\u001b[0m                   'model_sel.onnx', verbose=True, opset_version=12)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inps_one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "inps_one_hot_formatted = inps_one_hot.float()\n",
    "torch.onnx.export(model_sel, inps_one_hot_formatted,\n",
    "                  'model_sel.onnx', verbose=True, opset_version=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
