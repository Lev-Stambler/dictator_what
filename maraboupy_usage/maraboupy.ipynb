{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = 'EleutherAI/pythia-160m'\n",
    "model_name = 'EleutherAI/pythia-70m'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model_og = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python auto_gen_components.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[25521,  1533]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_input_after_tokenizer(inp: str):\n",
    "\t\ttokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\t\tinp_out = tokenizer(inp, return_tensors=\"pt\")\n",
    "\t\tprint(inp_out)\n",
    "\t\tinputs = inp_out['input_ids'].squeeze(0)\n",
    "\t\t# print(inputs, inputs.shape)\n",
    "\t\t# TODO: IDK ABOUT WHATS GOING ON W/ TOKEN SIZE VS Vocab Size\n",
    "\t\t# Vocab size is 50204 and inp size is 50304\n",
    "\t\tone_hot = torch.zeros((inputs.shape[0], 50304), dtype=torch.int)\n",
    "\t\tfor i in range(inputs.shape[0]):\n",
    "\t\t\tone_hot[i, inputs[i]] = 1\n",
    "\t\t# one_hot[inputs['input_ids'][0, 0]] = 1\n",
    "\t\treturn one_hot#, inp_out['attention_mask']\n",
    "get_input_after_tokenizer('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[25521,  1533]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "inps_one_hot = get_input_after_tokenizer(\"hello world\")\n",
    "seq_len = inps_one_hot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXLayer(\n",
       "  (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (attention): GPTNeoXAttention(\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "    (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (mlp): GPTNeoXMLP(\n",
       "    (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (act): GELUActivation()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_og.gpt_neox.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelSel(\n",
       "  (embed_linear): Linear(in_features=50304, out_features=512, bias=False)\n",
       "  (layer_norm): SimplfiedLayerNorm(\n",
       "    (eps): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (ones_linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (ones_linear_neg): Linear(in_features=512, out_features=512, bias=False)\n",
       "  )\n",
       "  (attn): FixedAttentionMask(\n",
       "    (attn): GPTNeoXAttention(\n",
       "      (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "      (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (slice_query): Slicer(\n",
       "      (slicer): Linear(in_features=192, out_features=64, bias=True)\n",
       "    )\n",
       "    (slice_value): Slicer(\n",
       "      (slicer): Linear(in_features=192, out_features=64, bias=True)\n",
       "    )\n",
       "    (slice_key): Slicer(\n",
       "      (slicer): Linear(in_features=192, out_features=64, bias=True)\n",
       "    )\n",
       "    (slice_rotary): Slicer(\n",
       "      (slicer): Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (slice_non_rotary): Slicer(\n",
       "      (slicer): Linear(in_features=64, out_features=48, bias=True)\n",
       "    )\n",
       "    (slice_rorate_half_1): Slicer(\n",
       "      (slicer): Linear(in_features=16, out_features=8, bias=True)\n",
       "    )\n",
       "    (slice_rorate_half_2): Slicer(\n",
       "      (slicer): Linear(in_features=16, out_features=8, bias=True)\n",
       "    )\n",
       "    (QKV_copier): QKVCopier(\n",
       "      (slicer_0): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_1): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_2): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_3): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_4): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_5): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_6): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "      (slicer_7): Slicer(\n",
       "        (slicer): Linear(in_features=1536, out_features=192, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simplified import ModelSel\n",
    "\n",
    "model_sel = ModelSel(model_og)\n",
    "model_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1536])\n",
      "QKV SIZE torch.Size([2, 1536]) torch.Size([2])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps_one_hot_formatted = inps_one_hot.float()\n",
    "# embed_linear.forward(inps_one_hot).shape\n",
    "model_sel(inps_one_hot_formatted).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1536])\n",
      "QKV SIZE torch.Size([2, 1536]) torch.Size([2])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:557: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len > self.max_seq_len_cached:\n",
      "/home/lev/code/research/dictator_what/maraboupy_usage/tmp/attn_head.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if key_length > self.bias.shape[-1]:\n",
      "/home/lev/code/research/dictator_what/maraboupy_usage/tmp/attn_head.py:78: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask_value = torch.tensor(mask_value, dtype=attn_scores.dtype).to(attn_scores.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n",
      "torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2, 16]) torch.Size([2])\n",
      "ATTN OUTPUT torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64]) torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "inps_one_hot_formatted = inps_one_hot.float()\n",
    "torch.onnx.export(model_sel, inps_one_hot_formatted,\n",
    "                  'model_sel.onnx')\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Maraboupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'maraboupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15033/824079744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Path to Marabou folder if you did not export it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/lev/code/research/ai/dictator/Marabou'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaraboupy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarabou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'maraboupy'"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=\"$PYTHONPATH:/home/lev/code/research/ai/dictator/Marabou\"\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "## %\n",
    "# Path to Marabou folder if you did not export it\n",
    "sys.path.append('/home/lev/code/research/ai/dictator/Marabou')\n",
    "from maraboupy import Marabou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Marabou.createOptions(verbosity = 1)\n",
    "print(\"Simple Attention Head\")\n",
    "filename = \"model_sel.onnx\"\n",
    "network = Marabou.read_onnx(filename)#, inputNames=inputNames, outputNames=[outputName])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
